{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LZ4T_UWC9PYG"
   },
   "source": [
    "# Convolutional Neural Networks:\n",
    "\n",
    "> CNN's are slightly differently structured than standard neural nets, CNN's use a special layer called convolution layer which is used to detect edges and other features from the image. CNN's generally perform better than MLP's when it comes to image related tasks. CNN's architecture is different due to Convolution layer.\n",
    "> CNN's also train faster than normal MLP due to optimizations done to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "xCbpbR-v23yp",
    "outputId": "21e51d62-9e0b-4f79-9857-96de9c4e9301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12070121724317991869\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 7687752397963160232\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 16725446652765615580\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11281553818\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 1978926107946698973\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib \n",
    "from tqdm import tqdm # This will be used to get the time taken taken for each epoch.\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ct2Q2X4D3DoC"
   },
   "outputs": [],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "colab_type": "code",
    "id": "27-qcLYi3G8c",
    "outputId": "860e6b91-d75b-4baa-f15c-56cd312d6859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-07c0780416e4>:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting FFNN/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting FFNN/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting FFNN/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting FFNN/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "(55000, 784)\n",
      "(55000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST data on which we will train the LeNet\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os\n",
    "path = \"FFNN/\"\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "mnist = input_data.read_data_sets(path, one_hot=True)\n",
    "\n",
    "print(mnist.train.images.shape)\n",
    "print(mnist.train.labels.shape)\n",
    "print(mnist.test.images.shape)\n",
    "print(mnist.test.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PPys6sO53I4c"
   },
   "outputs": [],
   "source": [
    "# None represents n number of images, img_size 2 times represnts the shape of image, 1 is used for channels in image.\n",
    "# Since we have a black and white image channel is 1 , if we had RGB images channel would have been 3.\n",
    "# n channel basically means tensor has a depth of n i.e tensor size is img_sizeXimg_sizeXchannel_number.\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y_true = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fio0OtKN3q5u"
   },
   "outputs": [],
   "source": [
    "# Splitting the data into train and test.\n",
    "trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PvBxafXe35-E"
   },
   "outputs": [],
   "source": [
    "# Reshaping feature matrices\n",
    "# Now we need to reshape the images in the form of 28*28\n",
    "trX = trX.reshape(-1, 28, 28, 1)\n",
    "teX = teX.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2873
    },
    "colab_type": "code",
    "id": "lyR2MZV5dNnG",
    "outputId": "011fbd97-04e3-40fc-c0d5-15169620f05b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.3803922 , 0.37647063, 0.3019608 , 0.46274513,\n",
       "        0.2392157 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.3529412 , 0.5411765 ,\n",
       "        0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 ,\n",
       "        0.9215687 , 0.9843138 , 0.9843138 , 0.9725491 , 0.9960785 ,\n",
       "        0.9607844 , 0.9215687 , 0.74509805, 0.08235294, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.54901963, 0.9843138 , 0.9960785 ,\n",
       "        0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "        0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "        0.9960785 , 0.9960785 , 0.9960785 , 0.7411765 , 0.09019608,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.8862746 , 0.9960785 , 0.81568635,\n",
       "        0.7803922 , 0.7803922 , 0.7803922 , 0.7803922 , 0.54509807,\n",
       "        0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 ,\n",
       "        0.5019608 , 0.8705883 , 0.9960785 , 0.9960785 , 0.7411765 ,\n",
       "        0.08235294, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.14901961, 0.32156864, 0.0509804 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.13333334, 0.8352942 , 0.9960785 , 0.9960785 ,\n",
       "        0.45098042, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.32941177, 0.9960785 , 0.9960785 ,\n",
       "        0.9176471 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.32941177, 0.9960785 , 0.9960785 ,\n",
       "        0.9176471 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.4156863 , 0.6156863 , 0.9960785 , 0.9960785 ,\n",
       "        0.95294124, 0.20000002, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.09803922, 0.45882356, 0.8941177 , 0.8941177 ,\n",
       "        0.8941177 , 0.9921569 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "        0.9960785 , 0.94117653, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.26666668,\n",
       "        0.4666667 , 0.86274517, 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "        0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "        0.9960785 , 0.5568628 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.14509805, 0.73333335, 0.9921569 ,\n",
       "        0.9960785 , 0.9960785 , 0.9960785 , 0.8745099 , 0.8078432 ,\n",
       "        0.8078432 , 0.29411766, 0.26666668, 0.8431373 , 0.9960785 ,\n",
       "        0.9960785 , 0.45882356, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.4431373 , 0.8588236 , 0.9960785 , 0.9490197 ,\n",
       "        0.89019614, 0.45098042, 0.34901962, 0.12156864, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.7843138 , 0.9960785 ,\n",
       "        0.9450981 , 0.16078432, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.6627451 , 0.9960785 , 0.6901961 , 0.24313727,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.18823531, 0.9058824 , 0.9960785 ,\n",
       "        0.9176471 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.48627454, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.32941177, 0.9960785 , 0.9960785 ,\n",
       "        0.6509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.54509807, 0.9960785 , 0.9333334 ,\n",
       "        0.22352943, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.8235295 , 0.9803922 , 0.9960785 , 0.65882355,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.9490197 , 0.9960785 , 0.93725497, 0.22352943,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.34901962, 0.9843138 , 0.9450981 , 0.3372549 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01960784,\n",
       "        0.8078432 , 0.96470594, 0.6156863 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01568628,\n",
       "        0.45882356, 0.27058825, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trX[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "WWRR2-ob3_CO",
    "outputId": "f91a0623-964d-40f0-aad6-0d4addc77f8b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6e1bf24240>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(trX[0,:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "aEN7Ot524FvV",
    "outputId": "228d4855-1e3e-40da-f598-340b3bf4ccc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "(55000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(trX.shape)\n",
    "print(teX.shape)\n",
    "print(trY.shape)\n",
    "print(teY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gVxvkUvX8anN",
    "outputId": "d8a4542f-1209-4c5a-caa2-e44c31342311"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u4yTlSTm9L8z"
   },
   "source": [
    "## Training some CNN's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N-tj8OQU9BkL"
   },
   "outputs": [],
   "source": [
    "# Lets define some parameters for training -\n",
    "epochs = 15\n",
    "batch_size = 128\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oE4kRmjT9vTQ"
   },
   "outputs": [],
   "source": [
    "# Defining the place holders for X and Y which will be used for training :\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y_true = tf.placeholder(tf.float32, [None, num_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4KZ1YV4-HGW"
   },
   "source": [
    "### A) CNN with 2 Convolutional Layers followed by 1 Max Pooling Layer:\n",
    "\n",
    "1. Let 1st convo layer have 32 kernel matrices.\n",
    "2. Second convo layer have 64 kernel matrices.\n",
    "3. MaxPooling with matrix size of 2X2 stride of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8rSFi1il99Gv"
   },
   "outputs": [],
   "source": [
    "# Provide initial weights to Layer Neurons.\n",
    "def initial_weights(shape):\n",
    "  return tf.Variable( tf.random_normal(shape, stddev = 0.01) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Saw9YPEq_TvF"
   },
   "outputs": [],
   "source": [
    "# Defining the architecture here\n",
    "\n",
    "# 1st Convolutional Layer has kernel matrix size of 3X3 and there are 32 sych kernel matrices and each image has 1 channel.\n",
    "w_convo1 = initial_weights([3, 3, 1, 32]) # 3X3 kernel matrices and 32 number of them, stored as 4d tensor.\n",
    "\n",
    "w_convo2 = initial_weights([3, 3, 32, 64]) # 3X3 Kernel Matrices each taking input from all 32 outputs of conv layer 1 and generating 64 outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMjyOyTtAQmS"
   },
   "outputs": [],
   "source": [
    "w_dense = initial_weights([28*28*64, 128]) # Output generated after maxpooling and flattening will have 28*28*64 length vector .\n",
    "# We will pass this weight vector to a 128 neuron layer which is dense.\n",
    "\n",
    "w_output = initial_weights([128, num_classes]) # Takes the output from dense and gets 10 output to form output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wskX7pt7AS3b"
   },
   "outputs": [],
   "source": [
    "def CNNOne(X, w_convo1, w_convo2, w_dense, w_output):\n",
    "  # First convolutional layer will work directly on the images of 28X28.\n",
    "  \n",
    "  #strides tells us how many cells to skip after woring on current submatrix of the image matrix.\n",
    "  conv1 = tf.nn.conv2d(X, w_convo1, strides=[1,1,1,1], padding='SAME') # Padding = SAME keeps matrix dimensions to be same.\n",
    "  print(conv1.get_shape())\n",
    "  # The 32 outputs of conv1 is fed to relu to introduce non linearity.\n",
    "  conv1 = tf.nn.relu(conv1)\n",
    "  \n",
    "  # Second convolutional layer works on 32 outputs generated by first conv1 layer.\n",
    "  \n",
    "  conv2 = tf.nn.conv2d(conv1, w_convo2, strides=[1,1,1,1], padding='SAME') \n",
    "  conv2 = tf.nn.relu(conv2)\n",
    "  print(conv2.get_shape())\n",
    "  # Now adding the max pooling layer..\n",
    "  maxPool_op = tf.nn.max_pool(conv2, ksize=[1,2,2,1], strides=[1,1,1,1], padding='SAME') # ksize is pooling matrix size..\n",
    "  print(maxPool_op.get_shape())\n",
    "  # the output of max pooling is then flattened.\n",
    "  maxPool_op = tf.reshape(maxPool_op, [-1, 28*28*64])\n",
    "  print(maxPool_op.get_shape())\n",
    "  # This output is to be passed onto dense layer..\n",
    "  \n",
    "  dense_output = tf.matmul(maxPool_op, w_dense)\n",
    "  dense_output = tf.nn.relu(dense_output)\n",
    "  \n",
    "  # Output of dense is passed to output layer..\n",
    "  \n",
    "  output = tf.nn.sigmoid( tf.matmul(dense_output, w_output) )\n",
    "  \n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "8t7e8djbFvBA",
    "outputId": "1e567d7f-d123-43f2-8419-7d966a429ec6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 28, 28, 32)\n",
      "(?, 28, 28, 64)\n",
      "(?, 28, 28, 64)\n",
      "(?, 50176)\n"
     ]
    }
   ],
   "source": [
    "predictions = CNNOne(X, w_convo1, w_convo2, w_dense, w_output)\n",
    "cost = tf.nn.softmax_cross_entropy_with_logits_v2(logits = predictions, labels=Y_true)\n",
    "loss = tf.reduce_mean(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kDqDFjIcGkkK"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K3KNkmA7IkMD"
   },
   "outputs": [],
   "source": [
    "predict_op = tf.argmax(predictions, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "DI01cPHcKAYC",
    "outputId": "9c006888-caa3-4b52-d48e-5bc61763e460"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 :   Accuracy on Test Data : 0.9270833333333334\n",
      "Epoch  2 :   Accuracy on Test Data : 0.9677483974358975\n",
      "Epoch  3 :   Accuracy on Test Data : 0.9758613782051282\n",
      "Epoch  4 :   Accuracy on Test Data : 0.9787660256410257\n",
      "Epoch  5 :   Accuracy on Test Data : 0.9816706730769231\n",
      "Epoch  6 :   Accuracy on Test Data : 0.9822716346153846\n",
      "Epoch  7 :   Accuracy on Test Data : 0.9808693910256411\n",
      "Epoch  8 :   Accuracy on Test Data : 0.9816706730769231\n",
      "Epoch  9 :   Accuracy on Test Data : 0.9826722756410257\n",
      "Epoch 10 :   Accuracy on Test Data : 0.9828725961538461\n",
      "Epoch 11 :   Accuracy on Test Data : 0.9832732371794872\n",
      "Epoch 12 :   Accuracy on Test Data : 0.9838741987179487\n",
      "Epoch 13 :   Accuracy on Test Data : 0.9840745192307693\n",
      "Epoch 14 :   Accuracy on Test Data : 0.9852764423076923\n",
      "Epoch 15 :   Accuracy on Test Data : 0.9868790064102564\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config = tf.ConfigProto(log_device_placement = True)) as sess:\n",
    "  tf.global_variables_initializer().run()\n",
    "  for i in range(epochs):\n",
    "    training_batch =  zip(range(0, len(trX), batch_size), range(batch_size, len(trX)+1, batch_size))\n",
    "    for start, end in training_batch:\n",
    "      sess.run(optimizer, feed_dict={X: trX[start:end],Y_true: trY[start:end]})\n",
    "      \n",
    "    test_batch =  zip(range(0, len(teX), batch_size), range(batch_size, len(teX)+1, batch_size))\n",
    "    co = 0\n",
    "    avg = 0\n",
    "    for start, end in test_batch:\n",
    "      avg += np.mean(np.argmax(teY[start:end], axis=1) == sess.run(predict_op,feed_dict={X: teX[start:end], Y_true: teY[start:end]}))\n",
    "      co += 1\n",
    "    \n",
    "    avg /= co\n",
    "  \n",
    "    print(\"Epoch {:2d} : \".format(i+1), \" Accuracy on Test Data :\", avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7LinjRriSQoj"
   },
   "source": [
    "### B) CNN with 2 Convolution Layer and 2 Max Pooling Layer:\n",
    "\n",
    "1. First layer is convolution layer with 32 Kernels.\n",
    "2. Second Layer is Max pooling Layer.\n",
    "3. Third Layer is convolution layer with 64 Kernels.\n",
    "4. Another Max Pooling Layer.\n",
    "5. Dense Layer with 128 Neurons.\n",
    "6. Output Layer with 10 neurons one for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7fi5IdzhUP2X"
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'c1': tf.Variable( tf.random_normal( [3, 3, 1, 32], stddev =0.01 ) ),\n",
    "    'c2': tf.Variable( tf.random_normal( [3, 3, 32, 64], stddev = 0.01 ) ),\n",
    "    'dense': tf.Variable( tf.random_normal( [13*13*64, 128], stddev = 0.01 ) ),\n",
    "    'out': tf.Variable( tf.random_normal( [128, 10], stddev = 0.01 ) )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TT_b6_FHUR6t"
   },
   "outputs": [],
   "source": [
    "def CNNTwo(X, weights):\n",
    "  # First layer interacts with the input tensor directly and generates 32 outputs.\n",
    "  conv1 = tf.nn.conv2d(X, weights['c1'], strides=[1,1,1,1], padding='SAME')\n",
    "  conv1 = tf.nn.relu(conv1) \n",
    "  print(\"Conv1 : \", conv1.get_shape())\n",
    "  \n",
    "  # Now max pooling layer\n",
    "  maxpool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "  print(\"MaxPool1 : \", maxpool1.get_shape())\n",
    "  \n",
    "  # New shape of the matrix will be - [(n - k)/s] + 1 = (28 - 2)/2 + 1 = 14 (lower integer or floor value)\n",
    "  conv2 = tf.nn.conv2d(maxpool1, weights['c2'], strides=[1,1,1,1], padding='SAME')\n",
    "  conv2 = tf.nn.relu(conv2)\n",
    "  print(\"Conv2 : \", conv2.get_shape())\n",
    "  \n",
    "  #Again Max Pooling\n",
    "  maxpool2 = tf.nn.max_pool(conv2, ksize=[1,2,2,1], strides=[1,1,1,1], padding='VALID')\n",
    "  print(\"MaxPool2 : \", maxpool2.get_shape())\n",
    "  \n",
    "  # New shape of the matrix will be 14-2+1 = 13\n",
    "  # Dense layer will have 13*13*64 neurons as conv2 layer generates 64 outputs.\n",
    "  # Dense layer will recieve these as a vector of size 12*12*64.\n",
    "  # so we need to reshape it\n",
    "  reshaped_vector = tf.reshape(maxpool2, [-1, 13*13*64])\n",
    "  print(\"Vector flattened : \", reshaped_vector.get_shape())\n",
    "  \n",
    "  dense_output = tf.nn.relu( tf.matmul(reshaped_vector, weights['dense'] ) )\n",
    "  print(\"Dense output : \", dense_output.get_shape())\n",
    "  \n",
    "  final_output = tf.nn.sigmoid( tf.matmul(dense_output, weights['out'] ) )\n",
    "  \n",
    "  return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "p9afKJNiZXo2",
    "outputId": "00ee2379-4802-4191-89c7-8b8957631518"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1 :  (?, 28, 28, 32)\n",
      "MaxPool1 :  (?, 14, 14, 32)\n",
      "Conv2 :  (?, 14, 14, 64)\n",
      "MaxPool2 :  (?, 13, 13, 64)\n",
      "Vector flattened :  (?, 10816)\n",
      "Dense output :  (?, 128)\n"
     ]
    }
   ],
   "source": [
    "predictions = CNNTwo(X, weights)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = predictions, labels=Y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NbWfuahJZhWg"
   },
   "outputs": [],
   "source": [
    "accuracy, acc_op = tf.metrics.accuracy(labels = tf.argmax(Y_true, 1), predictions=tf.argmax(predictions, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MqGrDIEZakfW"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "G2cLrCf0alh3",
    "outputId": "db228122-669c-43d3-b8ab-d8b01c9701bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 :   Accuracy on Test Data : 0.9505820572376251\n",
      "Epoch  2 :   Accuracy on Test Data : 0.9599578388226337\n",
      "Epoch  3 :   Accuracy on Test Data : 0.9656658317798223\n",
      "Epoch  4 :   Accuracy on Test Data : 0.968930755670254\n",
      "Epoch  5 :   Accuracy on Test Data : 0.9708584111470443\n",
      "Epoch  6 :   Accuracy on Test Data : 0.9723957349092532\n",
      "Epoch  7 :   Accuracy on Test Data : 0.9736283222834269\n",
      "Epoch  8 :   Accuracy on Test Data : 0.975015198573088\n",
      "Epoch  9 :   Accuracy on Test Data : 0.9761576171104724\n",
      "Epoch 10 :   Accuracy on Test Data : 0.9770491902644818\n",
      "Epoch 11 :   Accuracy on Test Data : 0.977892028215604\n",
      "Epoch 12 :   Accuracy on Test Data : 0.9785804779101641\n",
      "Epoch 13 :   Accuracy on Test Data : 0.9791794304664319\n",
      "Epoch 14 :   Accuracy on Test Data : 0.9797021463895456\n",
      "Epoch 15 :   Accuracy on Test Data : 0.9799828903797345\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config = tf.ConfigProto(log_device_placement = True)) as sess:\n",
    "  tf.global_variables_initializer().run()\n",
    "  tf.local_variables_initializer().run()\n",
    "  for i in range(epochs):\n",
    "    training_batch =  zip(range(0, len(trX), batch_size), range(batch_size, len(trX)+1, batch_size))\n",
    "    for start, end in training_batch:\n",
    "      sess.run(optimizer, feed_dict={X: trX[start:end],Y_true: trY[start:end]})\n",
    "      \n",
    "    test_batch =  zip(range(0, len(teX), batch_size), range(batch_size, len(teX)+1, batch_size))\n",
    "    co = 0\n",
    "    avg = 0\n",
    "    for start, end in test_batch:\n",
    "      avg += sess.run(acc_op, feed_dict={X: teX[start:end], Y_true: teY[start:end]})\n",
    "      co += 1\n",
    "    \n",
    "    avg /= co\n",
    "  \n",
    "    print(\"Epoch {:2d} : \".format(i+1), \" Accuracy on Test Data :\", avg)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "4-Convolutional Neural Networks.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
