{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Networks :\n",
    "\n",
    "A fully connected neural network which comprises of n hidden layer and 1 input and 1 output layer.\n",
    "\n",
    "** Types: **\n",
    "1. Multi-Layer Perceptrons.\n",
    "2. Deep Belief Networks.\n",
    "3. Stacked AutoEncoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakhar\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-139008f84df9>:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\Prakhar\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\Prakhar\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting FFNN/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Prakhar\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting FFNN/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Prakhar\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting FFNN/t10k-images-idx3-ubyte.gz\n",
      "Extracting FFNN/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Prakhar\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# Saving images to file in HDD..\n",
    "import os\n",
    "path = \"FFNN/\"\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "inp_data = input_data.read_data_sets(path, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(55000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(inp_data.train.images.shape)\n",
    "print(inp_data.train.labels.shape)\n",
    "print(inp_data.test.images.shape)\n",
    "print(inp_data.test.labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize a single image :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "img = inp_data.train.images[0]\n",
    "img = np.resize(img, (28,28))\n",
    "lab = inp_data.train.labels[0]\n",
    "print(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADaxJREFUeJzt3W2IHfUVx/HfyUMVNooJMTHYVNsiTesKsSyxEi0rkqKlGCM0JkJJsbgKTayo0JgXMSCVWmofQCxuMTRCYhNpa/Ki2oo0mmIRs1F8aGyrdRu3WRMlJTWIiUlOX+ykrHHnPzf3zty5u+f7Adl758zD4Zrfztydh7+5uwDEM6nuBgDUg/ADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwhqSjs3ZmZcTghUzN2tkfla2vOb2VVm9jcze8PMVreyLgDtZc1e229mkyX9XdIiSUOSXpC03N3/mliGPT9QsXbs+RdIesPd/+nuRyT9WtLiFtYHoI1aCf+5kt4e9X4om/YxZtZnZjvNbGcL2wJQslb+4DfWocUnDuvdvV9Sv8RhP9BJWtnzD0maO+r9pyXtba0dAO3SSvhfkHSBmX3WzD4laZmkbeW0BaBqTR/2u/tRM1sp6Q+SJkta7+6vldYZgEo1faqvqY3xnR+oXFsu8gEwfhF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QVNNDdEuSmQ1Kel/SMUlH3b2njKYAVK+l8GeucPf3SlgPgDbisB8IqtXwu6Q/mtmAmfWV0RCA9mj1sH+hu+81s1mSnjKz19392dEzZL8U+MUAdBhz93JWZLZO0iF3/3FinnI2BiCXu1sj8zV92G9mXWZ2xonXkr4m6dVm1wegvVo57J8t6XdmdmI9m9z9yVK6AlC50g77G9oYh/1A5So/7AcwvhF+ICjCDwRF+IGgCD8QFOEHgirjrj7U7M4778ytFZ3Kfe+99A2Z3d3dyfqOHTuS9W3btiXrqA97fiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IasLc0rtq1apk/ZJLLknWr7vuujLbaavTTjut6WWL/v9Pnjw5Wf/oo4+S9aNHj+bW9uzZk1y2t7c3WX/nnXeS9ai4pRdAEuEHgiL8QFCEHwiK8ANBEX4gKMIPBDWuzvNv2rQpt3b99dcnl500id9z483rr7+erF955ZXJ+t69e8tsZ9zgPD+AJMIPBEX4gaAIPxAU4QeCIvxAUIQfCKrwPL+ZrZf0DUn73b07mzZD0mZJ50salLTU3f9TuLEWz/MfPHgwt3bmmWcmly0653vkyJGmeirDc889l6xv3ry5TZ2cuquvvjpZX7ZsWW7trLPOamnbRdcBXHHFFbm1ifwsgDLP8/9K0lUnTVst6Wl3v0DS09l7AONIYfjd/VlJB06avFjShuz1BknXltwXgIo1+51/trsPS1L2c1Z5LQFoh8rH6jOzPkl9VW8HwKlpds+/z8zmSFL2c3/ejO7e7+497t7T5LYAVKDZ8G+TtCJ7vULS1nLaAdAuheE3s0cl/UXSF8xsyMy+I+mHkhaZ2T8kLcreAxhHxtX9/BdddFFurei5/I899liynrqGAM2bN29ebu2ZZ55JLjtrVmt/R77vvvtya6tXT9yz09zPDyCJ8ANBEX4gKMIPBEX4gaAIPxDUuDrVh4mlry991fdDDz3U0vo/+OCD3FpXV1dL6+5knOoDkET4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQVU+XBdiW7t2bW7t8ssvr3TbU6bk//Pu7e1NLrt9+/Zym+lA7PmBoAg/EBThB4Ii/EBQhB8IivADQRF+IKjC5/ab2XpJ35C03927s2nrJN0k6d1stjXu/vvCjfHc/krMnTs3t7Zq1arksrfcckvZ7XzMtGnTcmtmDT1evhKHDx9O1k8//fQ2dVK+Mp/b/ytJV40x/afuPj/7rzD4ADpLYfjd/VlJB9rQC4A2auU7/0oze9nM1pvZ9NI6AtAWzYb/F5I+L2m+pGFJ9+fNaGZ9ZrbTzHY2uS0AFWgq/O6+z92PuftxSb+UtCAxb7+797h7T7NNAihfU+E3szmj3i6R9Go57QBol8Jbes3sUUm9kmaa2ZCkuyX1mtl8SS5pUNLNFfYIoAKF4Xf35WNMfriCXsJaunRpsr5gQe63KknSjTfemFubPp2/xY7l8ccfr7uF2nGFHxAU4QeCIvxAUIQfCIrwA0ERfiAoHt1dgu7u7mR9y5Ytyfq8efOS9SpvfT148GCyfujQoZbWf9ddd+XWim6rfeCBB5L1s88+u6meJGnPnj1NLztRsOcHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAKH91d6sbG8aO777333tzazTenH2cwY8aMZP3IkSPJetH58AcffDC3NjQ0lFz2iSeeSNbffPPNZL1Kg4ODyfp5552XrKc+t0svvTS57Isvvpisd7IyH90NYAIi/EBQhB8IivADQRF+ICjCDwRF+IGguJ+/Qb29vbm1ovP4AwMDyfo999yTrG/dujVZH68WLlyYrM+cObOl9R87diy3Np7P45eFPT8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBFV4nt/M5kp6RNI5ko5L6nf3n5vZDEmbJZ0vaVDSUnf/T3Wt1uuaa67Jra1duza57K233lp2OxPChRdemKx3dXW1tP5du3a1tPxE18ie/6ikO9z9i5K+Ium7ZvYlSaslPe3uF0h6OnsPYJwoDL+7D7v7ruz1+5J2SzpX0mJJG7LZNki6tqomAZTvlL7zm9n5ki6W9Lyk2e4+LI38gpA0q+zmAFSn4Wv7zWyapN9Ius3d/9vo+HFm1iepr7n2AFSloT2/mU3VSPA3uvtvs8n7zGxOVp8jaf9Yy7p7v7v3uHtPGQ0DKEdh+G1kF/+wpN3u/pNRpW2SVmSvV0iamLeeARNU4aO7zewySTskvaKRU32StEYj3/u3SPqMpD2SvunuBwrWNW4f3Y3ybdy4MVm/4YYbkvUPP/wwWV+yZElu7cknn0wuO541+ujuwu/87v5nSXkru/JUmgLQObjCDwiK8ANBEX4gKMIPBEX4gaAIPxAUj+5GpYaHh3Nrs2a1djtI0S27E/lcfhnY8wNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUJznR6VSw5dPmpTe9xTdr180tDnS2PMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCc50dLVq5cmaxPmZL/T+zw4cPJZW+//fZknfv1W8OeHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCMndPz2A2V9Ijks6RdFxSv7v/3MzWSbpJ0rvZrGvc/fcF60pvDB1n6tSpyfpbb72VrM+ePTu3tn379uSyixYtStYxNne3RuZr5CKfo5LucPddZnaGpAEzeyqr/dTdf9xskwDqUxh+dx+WNJy9ft/Mdks6t+rGAFTrlL7zm9n5ki6W9Hw2aaWZvWxm681ses4yfWa208x2ttQpgFI1HH4zmybpN5Juc/f/SvqFpM9Lmq+RI4P7x1rO3fvdvcfde0roF0BJGgq/mU3VSPA3uvtvJcnd97n7MXc/LumXkhZU1yaAshWG38xM0sOSdrv7T0ZNnzNqtiWSXi2/PQBVaeSv/QslfUvSK2b2UjZtjaTlZjZfkksalHRzJR2iVkWngjdt2pSsDwwM5NY2b97cVE8oRyN/7f+zpLHOGybP6QPobFzhBwRF+IGgCD8QFOEHgiL8QFCEHwiq8JbeUjfGLb1A5Rq9pZc9PxAU4QeCIvxAUIQfCIrwA0ERfiAowg8E1e4hut+T9K9R72dm0zpRp/bWqX1J9NasMns7r9EZ23qRzyc2brazU5/t16m9dWpfEr01q67eOOwHgiL8QFB1h7+/5u2ndGpvndqXRG/NqqW3Wr/zA6hP3Xt+ADWpJfxmdpWZ/c3M3jCz1XX0kMfMBs3sFTN7qe4hxrJh0Pab2aujps0ws6fM7B/ZzzGHSaupt3Vm9u/ss3vJzL5eU29zzexPZrbbzF4zs+9l02v97BJ91fK5tf2w38wmS/q7pEWShiS9IGm5u/+1rY3kMLNBST3uXvs5YTP7qqRDkh5x9+5s2o8kHXD3H2a/OKe7+/c7pLd1kg7VPXJzNqDMnNEjS0u6VtK3VeNnl+hrqWr43OrY8y+Q9Ia7/9Pdj0j6taTFNfTR8dz9WUkHTpq8WNKG7PUGjfzjabuc3jqCuw+7+67s9fuSTowsXetnl+irFnWE/1xJb496P6TOGvLbJf3RzAbMrK/uZsYwOxs2/cTw6bNq7udkhSM3t9NJI0t3zGfXzIjXZasj/GM9YqiTTjksdPcvS7pa0nezw1s0pqGRm9tljJGlO0KzI16XrY7wD0maO+r9pyXtraGPMbn73uznfkm/U+eNPrzvxCCp2c/9Nffzf500cvNYI0urAz67Thrxuo7wvyDpAjP7rJl9StIySdtq6OMTzKwr+0OMzKxL0tfUeaMPb5O0Inu9QtLWGnv5mE4ZuTlvZGnV/Nl12ojXtVzkk53K+JmkyZLWu/sP2t7EGMzscxrZ20sjdzxuqrM3M3tUUq9G7vraJ+luSY9L2iLpM5L2SPqmu7f9D285vfVq5ND1/yM3n/iO3ebeLpO0Q9Irko5nk9do5Pt1bZ9doq/lquFz4wo/ICiu8AOCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/ENT/AOZpEMJau0xcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Building neural networks :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Five Layer Neural Network :\n",
    "\n",
    "1. Layer one - 200 Neurons Sigmoid act.\n",
    "2. Layer two - 100 Neurons Sigmoid act.\n",
    "3. Layer three - 60 Neurons Sigmoid act.\n",
    "4. Layer four - 30 Neurons Sigmoid act.\n",
    "5. Layer five - 10 Neurons Softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorflow.python.framework import ops\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting FFNN/train-images-idx3-ubyte.gz\n",
      "Extracting FFNN/train-labels-idx1-ubyte.gz\n",
      "Extracting FFNN/t10k-images-idx3-ubyte.gz\n",
      "Extracting FFNN/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "logs_path = 'log_sigmoid/' # logging path\n",
    "batch_size = 100 # batch size while performing training \n",
    "learning_rate = 0.003 # Learning rate \n",
    "training_epochs = 10 # training epoch\n",
    "display_epoch = 1\n",
    "mnist = input_data.read_data_sets(path, one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the input layer :\n",
    "\n",
    "Input layer a 2d tensor which consist of n samples, each sample has 784 dimensions. Since the number of samples in training dataset can vary, we specify variable number of rows using the \"None\" option when declaring shape of tensor. Also the tensor which will hold the train data will be a placeholder as it does not need any modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 784], name=\"InputData\") # tensor of input data of size n*784 dimensions\n",
    "XX = tf.reshape(X, [-1, 784]) # -1 is to transpose\n",
    "Y_ = tf.placeholder(tf.float32, [None, 10], name=\"LabelData\") # tensor of labels of size n*784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the first Layer :\n",
    "\n",
    "Each node in the first layer recieves the pixels of the image combined with the weights and bias term. This layer contains 200 Neurons.\n",
    "\n",
    "Each node recieves the input as - inp = w(transpose) * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 200\n",
    "# Since the data is 784 dimensional there must be 784 weights and 1 bias.\n",
    "W1 = tf.Variable(tf.truncated_normal([784, L], stddev=0.1)) # initializing random weights for layer 1.\n",
    "B1 = tf.Variable(tf.zeros([L])) # Bias vector for layer 2.\n",
    "\n",
    "# The output is calculated as wtranspose * x + b or xtranspose * w + b and then sigmoid function is applied on it.\n",
    "Y1 = tf.nn.sigmoid(tf.matmul(XX, W1) + B1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the second Layer :\n",
    "\n",
    "The second layer recieves as input the output of previous layer that is Y1. And again multiples the Y1 with weights and adds a bias term to generate output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 100\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([L, M], stddev=0.1)) # initializing random weights for layer 2.\n",
    "B2 = tf.Variable(tf.zeros([M])) # Bias vector for layer 2.\n",
    "\n",
    "# The output now -\n",
    "Y2 = tf.nn.sigmoid(tf.matmul(Y1, W2) + B2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the third layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 60\n",
    "W3 = tf.Variable(tf.truncated_normal([M, N], stddev=0.1)) # Initialize random weights for the hidden layer 3 \n",
    "B3 = tf.Variable(tf.zeros([N])) # Bias vector for layer 3\n",
    "\n",
    "Y3 = tf.nn.sigmoid(tf.matmul(Y2, W3) + B3) # Output from layer 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the fourth layer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = 30\n",
    "W4 = tf.Variable(tf.truncated_normal([N, O], stddev=0.1)) # Initialize random weights for the hidden layer 4\n",
    "B4 = tf.Variable(tf.zeros([O])) # Bias vector for layer 4\n",
    "\n",
    "Y4 = tf.nn.sigmoid(tf.matmul(Y3, W4) + B4) # Output from layer 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the fifth layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "W5 = tf.Variable(tf.truncated_normal([O, 10], stddev=0.1)) # Initialize random weights for the hidden layer 5 \n",
    "B5 = tf.Variable(tf.zeros([10])) # Bias vector for layer 5\n",
    "Ylogits = tf.matmul(Y4, W5) + B5 # computing the logits\n",
    "Y = tf.nn.softmax(Ylogits)# output from layer 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-866b75129e90>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cross entropy is basically our logistics loss for multiclass.\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits, labels=Y_) # final outcome using softmax cross entropy\n",
    "cost_op = tf.reduce_mean(cross_entropy)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction is correct if output is equal to actual Y_ is actual, Y is predicted\n",
    "correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(cost_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"cost\", cost_op)\n",
    "# Create a summary to monitor accuracy tensor\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "# Merge all summaries into a single op\n",
    "summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Optimization Finished!\n",
      "Accuracy:  0.9735\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "with tf.Session() as sess:\n",
    "    # Run the initializer\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # op to write logs to TensorBoard\n",
    "    writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        batch_count = int(mnist.train.num_examples/batch_size)\n",
    "        for i in range(batch_count):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            _,summary = sess.run([train_op, summary_op], feed_dict={X: batch_x, Y_: batch_y})\n",
    "            writer.add_summary(summary, epoch * batch_count + i)\n",
    "               \n",
    "        print(\"Epoch: \", epoch)\n",
    "        \n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Accuracy: \", accuracy.eval(feed_dict={X: mnist.test.images, Y_: mnist.test.labels}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
