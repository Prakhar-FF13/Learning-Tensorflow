{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5-CNN LeNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Dsa5j__n1E-E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Networks :"
      ]
    },
    {
      "metadata": {
        "id": "BSRBYFoz1E-N",
        "colab_type": "code",
        "outputId": "ec6bb858-a7fc-4bc6-9aed-ef8866ec8c41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib \n",
        "from tqdm import tqdm # This will be used to get the time taken taken for each epoch.\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 897184562873584465\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 11787107827006311186\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 14991620147370909538\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 11281553818\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 74633642981109020\n",
            "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Pf67hsNb1E-k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HCIguRvA1E-x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## LeNet architecture CNN :\n",
        "\n",
        "> LeNet was the first CNN architecture that was discussed in the 19th century. This is one of the most simplest architecture which uses all the layers which can be added to a CNN network.\n",
        "\n",
        "<img src=\"LeNet.jpg\">"
      ]
    },
    {
      "metadata": {
        "id": "Z8KTfymN1E-4",
        "colab_type": "code",
        "outputId": "188a5e61-d7f5-4440-e615-dde874ae0f00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the MNIST data on which we will train the LeNet\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import os\n",
        "path = \"FFNN/\"\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "    \n",
        "mnist = input_data.read_data_sets(path, one_hot=True)\n",
        "\n",
        "print(mnist.train.images.shape)\n",
        "print(mnist.train.labels.shape)\n",
        "print(mnist.test.images.shape)\n",
        "print(mnist.test.labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-07c0780416e4>:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting FFNN/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting FFNN/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting FFNN/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting FFNN/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "(55000, 784)\n",
            "(55000, 10)\n",
            "(10000, 784)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d2h5MIiE1E_E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# First lets define the parameters for the architecture and parameters used in training the LeNet model :\n",
        "batch_size = 128 # Number of samples used in training phase.\n",
        "test_size = 256 # Number of samples used in testing phase.\n",
        "img_size = 28 # Image size of 28X28\n",
        "num_classes = 10 # 0-9 digits classifictaion task."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1os7W_Kc1E_L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# None represents n number of images, img_size 2 times represnts the shape of image, 1 is used for channels in image.\n",
        "# Since we have a black and white image channel is 1 , if we had RGB images channel would have been 3.\n",
        "# n channel basically means tensor has a depth of n i.e tensor size is img_sizeXimg_sizeXchannel_number.\n",
        "X = tf.placeholder(tf.float32, [None, img_size, img_size, 1])\n",
        "Y_true = tf.placeholder(tf.float32, [None, num_classes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EXFx9DL_1E_U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trX, trY, teX, teY = mnist.train.images, \\\n",
        "                     mnist.train.labels, \\\n",
        "                     mnist.test.images,  \\\n",
        "                     mnist.test.labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t2gMcvIu1E_b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Now we need to reshape the images in the form of 28*28\n",
        "trX = trX.reshape(-1, img_size, img_size, 1)\n",
        "teX = teX.reshape(-1, img_size, img_size, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xmOOrVrN1E_l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Defining network weights :"
      ]
    },
    {
      "metadata": {
        "id": "0fwTm49C1E_p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def init_weights(shape):\n",
        "    # we keep simple initialization.\n",
        "    # Xavier, Glorot or He Normal can be used for initialization too.\n",
        "    return tf.Variable(tf.random_normal(shape, stddev=0.01)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hSLkAV3Q1E_v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# According to the Image of our architecture we need a convolution layer of 3X3 with depth of 1 as image is of depth 1.\n",
        "# So basically a Kernel Matrix which is used to get the features from the image is of size 3X3X1 is present for this layer.\n",
        "# We are having 32 Convolutional Layers. so we either declare 32 - 3X3X1 matrices or declare one of size 3X3X1X32.\n",
        "# Second method will be useful as all layers are in matrix together, so we can parallelize them.\n",
        "w1 = init_weights([3, 3, 1, 32]) # shape is passed as parameter\n",
        "\n",
        "# Note this layer will output 32 2d matrices so basically a 3d tensor with depth of 32 and width and height of 28-3+1 = 26"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k9aJN74y1E_3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We will add pooling layer later first lets just define the weights\n",
        "w2 = init_weights([3, 3, 32, 64]) # Here depth is 32 as we recievce 32 from first conv layer and we output 64 this time."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xzAcZZhc1E_9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "w3 = init_weights([3, 3, 64, 128])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pmYHGGOh1FAE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fourth layer is fully connected and hence the output is a weight vector which is recieved after flattening..\n",
        "w4 = init_weights([128 * 4 * 4, 625]) # The numbers here will make more sense when we actually define the graph."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1pDJZ9m31FAM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The output layer will take in these 625 features and provide 10 output as we have 10 classes.\n",
        "w_o = init_weights([625, num_classes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4RLWYT8y1FAU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# DropOut Values\n",
        "p_keep_conv = tf.placeholder(\"float\") \n",
        "p_keep_hidden = tf.placeholder(\"float\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GZ76p9V91FAY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Defining a LeNet Copy function as we are trying to mimic LeNet architecture..\n",
        "def LeNetCopy(X, w, w2, w3, w4, w_o, p_keep_conv, p_keep_hidden):\n",
        "    # tf.nn.conv2d adds a convolution layer..\n",
        "    # the function expected the image which is to be convolved and kernel matrices, we defined our kernel matrices in w1.\n",
        "    # Strides basically tell how much to move the kernel matrix after operating on part of the image.\n",
        "    # Padding adds additional columns and rows to keep the shape of image same after convolving..\n",
        "    conv1 = tf.nn.conv2d(X, w1, strides=[1,1,1,1], padding='SAME') # Keep the same dimensions of image after convoling\n",
        "    # The output shape of the tensor obtained is calculated as follows, depth = number of kernel matrices i.e 32 defined in w1.\n",
        "    # the number of rows and columns are calculated as n - k + 1 + 2p, here n = 28, k = 3 p is not givenbut.\n",
        "    # We know that dimensions of output matrix has to be constant i.e 28.\n",
        "    # So. n - k + 1 + 2p = 28 , solving gets us p = 1.\n",
        "    # p = 1 means that padding added 1 row and 1 column to get the tensor row and column dimensions same after convolving oper.\n",
        "    \n",
        "    # After convolving we pass the output through a relu layer.\n",
        "    conv1 = tf.nn.relu(conv1)\n",
        "    \n",
        "    # Now according to the architecture we have to pool the image.\n",
        "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "    # output = floor[(n-k+2p)/s + 1]. s = stride here s = 2 for both row and column\n",
        "    conv1 = tf.nn.dropout(conv1, p_keep_conv)\n",
        "    \n",
        "    # similarly we build other layers\n",
        "    conv2 = tf.nn.conv2d(conv1, w2, strides=[1, 1, 1, 1], padding='SAME')\n",
        "    conv2 = tf.nn.relu(conv2)\n",
        "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "    conv2 = tf.nn.dropout(conv2, p_keep_conv)\n",
        "\n",
        "    # There is no max-pool after layer 3.\n",
        "    conv3 = tf.nn.conv2d(conv2, w3, strides=[1, 1, 1, 1], padding='SAME')\n",
        "    conv3 = tf.nn.relu(conv3)\n",
        "    \n",
        "    # Fully connected layers are now added to the model ...\n",
        "    FC_layer = tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "    # Reshape the Fully connected layer i.e flatten the image to get a vector 625 length.\n",
        "    FC_layer = tf.reshape(FC_layer, [-1, w4.get_shape().as_list()[0]])\n",
        "    # Apply dropout..\n",
        "    FC_layer = tf.nn.dropout(FC_layer, p_keep_conv)\n",
        "    \n",
        "    # Similar to MLP.. not included bias here.\n",
        "    output_layer = tf.nn.relu(tf.matmul(FC_layer, w4))\n",
        "    output_layer = tf.nn.dropout(output_layer, p_keep_hidden)\n",
        "    \n",
        "    # Result is obtained after final weight matrix multiplication.\n",
        "    result = tf.matmul(output_layer, w_o)\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t5KuLenQ1FAd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "py_x = LeNetCopy(X, w1, w2, w3, w4, w_o, p_keep_conv, p_keep_hidden)\n",
        "Y_ = tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y_true,logits=py_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8-US-yA-1FAl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cost = tf.reduce_mean(Y_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2fFmn9C51FAq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pn8zq7z01FAx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predict_op = tf.argmax(py_x, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tlRo0IXW1FA2",
        "colab_type": "code",
        "outputId": "5b696590-484d-4d03-98ec-a74305c4ecff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
        "    tf.global_variables_initializer().run()\n",
        "    for i in range(100):\n",
        "        # Get the training and test batch..\n",
        "        training_batch =  zip(range(0, len(trX), batch_size), range(batch_size, len(trX)+1, batch_size))\n",
        "        for start, end in training_batch:\n",
        "            # Use Current train and test batch to train the model.\n",
        "            sess.run(optimizer, feed_dict={X: trX[start:end],Y_true: trY[start:end],p_keep_conv: 0.8,p_keep_hidden: 0.5})\n",
        "        \n",
        "        test_indices = np.arange(len(teX)) \n",
        "        np.random.shuffle(test_indices)\n",
        "        test_indices = test_indices[0:test_size]\n",
        "        \n",
        "        print(i, np.mean(np.argmax(teY[test_indices], axis=1) == sess.run(predict_op,feed_dict={X: teX[test_indices],\\\n",
        "                                     Y_true: teY[test_indices], \\\n",
        "                                     p_keep_conv: 1.0,\\\n",
        "                                     p_keep_hidden: 1.0})))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.96875\n",
            "1 0.984375\n",
            "2 0.9921875\n",
            "3 0.98828125\n",
            "4 0.99609375\n",
            "5 0.98828125\n",
            "6 1.0\n",
            "7 0.99609375\n",
            "8 0.98828125\n",
            "9 0.98828125\n",
            "10 0.98828125\n",
            "11 0.9921875\n",
            "12 0.9921875\n",
            "13 0.98046875\n",
            "14 0.9921875\n",
            "15 0.9921875\n",
            "16 1.0\n",
            "17 0.98828125\n",
            "18 0.984375\n",
            "19 1.0\n",
            "20 0.9921875\n",
            "21 0.984375\n",
            "22 0.9921875\n",
            "23 0.99609375\n",
            "24 0.99609375\n",
            "25 0.9921875\n",
            "26 0.99609375\n",
            "27 1.0\n",
            "28 0.99609375\n",
            "29 0.98828125\n",
            "30 1.0\n",
            "31 0.99609375\n",
            "32 0.98828125\n",
            "33 0.9921875\n",
            "34 0.9921875\n",
            "35 0.99609375\n",
            "36 0.99609375\n",
            "37 0.984375\n",
            "38 0.99609375\n",
            "39 0.9921875\n",
            "40 0.99609375\n",
            "41 0.9921875\n",
            "42 1.0\n",
            "43 0.98828125\n",
            "44 0.98828125\n",
            "45 0.98828125\n",
            "46 1.0\n",
            "47 0.9921875\n",
            "48 0.9921875\n",
            "49 0.99609375\n",
            "50 1.0\n",
            "51 0.99609375\n",
            "52 0.9921875\n",
            "53 0.9921875\n",
            "54 0.99609375\n",
            "55 0.9921875\n",
            "56 1.0\n",
            "57 1.0\n",
            "58 0.9921875\n",
            "59 0.9921875\n",
            "60 0.984375\n",
            "61 0.99609375\n",
            "62 1.0\n",
            "63 0.98828125\n",
            "64 0.9921875\n",
            "65 0.99609375\n",
            "66 0.99609375\n",
            "67 0.98828125\n",
            "68 1.0\n",
            "69 0.99609375\n",
            "70 0.98828125\n",
            "71 0.984375\n",
            "72 1.0\n",
            "73 0.99609375\n",
            "74 0.984375\n",
            "75 0.98828125\n",
            "76 0.9921875\n",
            "77 0.99609375\n",
            "78 0.99609375\n",
            "79 0.99609375\n",
            "80 1.0\n",
            "81 0.9921875\n",
            "82 0.9921875\n",
            "83 0.9921875\n",
            "84 0.9921875\n",
            "85 0.99609375\n",
            "86 0.99609375\n",
            "87 0.98828125\n",
            "88 0.9921875\n",
            "89 0.99609375\n",
            "90 0.99609375\n",
            "91 0.9921875\n",
            "92 1.0\n",
            "93 0.9921875\n",
            "94 1.0\n",
            "95 0.9921875\n",
            "96 0.99609375\n",
            "97 1.0\n",
            "98 0.98828125\n",
            "99 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o1Nkpjsn1FA6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}