{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Networks :\n",
    "\n",
    "A fully connected neural network which comprises of n hidden layer and 1 input and 1 output layer.\n",
    "\n",
    "** Types: **\n",
    "1. Multi-Layer Perceptrons.\n",
    "2. Deep Belief Networks.\n",
    "3. Stacked AutoEncoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakhar\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 249827831002235250\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-139008f84df9>:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\Prakhar\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\Prakhar\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting FFNN/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Prakhar\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting FFNN/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Prakhar\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting FFNN/t10k-images-idx3-ubyte.gz\n",
      "Extracting FFNN/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Prakhar\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# Saving images to file in HDD..\n",
    "import os\n",
    "path = \"FFNN/\"\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "inp_data = input_data.read_data_sets(path, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(55000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(inp_data.train.images.shape)\n",
    "print(inp_data.train.labels.shape)\n",
    "print(inp_data.test.images.shape)\n",
    "print(inp_data.test.labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize a single image :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "img = inp_data.train.images[0]\n",
    "img = np.resize(img, (28,28))\n",
    "lab = inp_data.train.labels[0]\n",
    "print(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADaxJREFUeJzt3W2IHfUVx/HfyUMVNooJMTHYVNsiTesKsSyxEi0rkqKlGCM0JkJJsbgKTayo0JgXMSCVWmofQCxuMTRCYhNpa/Ki2oo0mmIRs1F8aGyrdRu3WRMlJTWIiUlOX+ykrHHnPzf3zty5u+f7Adl758zD4Zrfztydh7+5uwDEM6nuBgDUg/ADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwhqSjs3ZmZcTghUzN2tkfla2vOb2VVm9jcze8PMVreyLgDtZc1e229mkyX9XdIiSUOSXpC03N3/mliGPT9QsXbs+RdIesPd/+nuRyT9WtLiFtYHoI1aCf+5kt4e9X4om/YxZtZnZjvNbGcL2wJQslb+4DfWocUnDuvdvV9Sv8RhP9BJWtnzD0maO+r9pyXtba0dAO3SSvhfkHSBmX3WzD4laZmkbeW0BaBqTR/2u/tRM1sp6Q+SJkta7+6vldYZgEo1faqvqY3xnR+oXFsu8gEwfhF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QVNNDdEuSmQ1Kel/SMUlH3b2njKYAVK+l8GeucPf3SlgPgDbisB8IqtXwu6Q/mtmAmfWV0RCA9mj1sH+hu+81s1mSnjKz19392dEzZL8U+MUAdBhz93JWZLZO0iF3/3FinnI2BiCXu1sj8zV92G9mXWZ2xonXkr4m6dVm1wegvVo57J8t6XdmdmI9m9z9yVK6AlC50g77G9oYh/1A5So/7AcwvhF+ICjCDwRF+IGgCD8QFOEHgirjrj7U7M4778ytFZ3Kfe+99A2Z3d3dyfqOHTuS9W3btiXrqA97fiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IasLc0rtq1apk/ZJLLknWr7vuujLbaavTTjut6WWL/v9Pnjw5Wf/oo4+S9aNHj+bW9uzZk1y2t7c3WX/nnXeS9ai4pRdAEuEHgiL8QFCEHwiK8ANBEX4gKMIPBDWuzvNv2rQpt3b99dcnl500id9z483rr7+erF955ZXJ+t69e8tsZ9zgPD+AJMIPBEX4gaAIPxAU4QeCIvxAUIQfCKrwPL+ZrZf0DUn73b07mzZD0mZJ50salLTU3f9TuLEWz/MfPHgwt3bmmWcmly0653vkyJGmeirDc889l6xv3ry5TZ2cuquvvjpZX7ZsWW7trLPOamnbRdcBXHHFFbm1ifwsgDLP8/9K0lUnTVst6Wl3v0DS09l7AONIYfjd/VlJB06avFjShuz1BknXltwXgIo1+51/trsPS1L2c1Z5LQFoh8rH6jOzPkl9VW8HwKlpds+/z8zmSFL2c3/ejO7e7+497t7T5LYAVKDZ8G+TtCJ7vULS1nLaAdAuheE3s0cl/UXSF8xsyMy+I+mHkhaZ2T8kLcreAxhHxtX9/BdddFFurei5/I899liynrqGAM2bN29ebu2ZZ55JLjtrVmt/R77vvvtya6tXT9yz09zPDyCJ8ANBEX4gKMIPBEX4gaAIPxDUuDrVh4mlry991fdDDz3U0vo/+OCD3FpXV1dL6+5knOoDkET4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQVU+XBdiW7t2bW7t8ssvr3TbU6bk//Pu7e1NLrt9+/Zym+lA7PmBoAg/EBThB4Ii/EBQhB8IivADQRF+IKjC5/ab2XpJ35C03927s2nrJN0k6d1stjXu/vvCjfHc/krMnTs3t7Zq1arksrfcckvZ7XzMtGnTcmtmDT1evhKHDx9O1k8//fQ2dVK+Mp/b/ytJV40x/afuPj/7rzD4ADpLYfjd/VlJB9rQC4A2auU7/0oze9nM1pvZ9NI6AtAWzYb/F5I+L2m+pGFJ9+fNaGZ9ZrbTzHY2uS0AFWgq/O6+z92PuftxSb+UtCAxb7+797h7T7NNAihfU+E3szmj3i6R9Go57QBol8Jbes3sUUm9kmaa2ZCkuyX1mtl8SS5pUNLNFfYIoAKF4Xf35WNMfriCXsJaunRpsr5gQe63KknSjTfemFubPp2/xY7l8ccfr7uF2nGFHxAU4QeCIvxAUIQfCIrwA0ERfiAoHt1dgu7u7mR9y5Ytyfq8efOS9SpvfT148GCyfujQoZbWf9ddd+XWim6rfeCBB5L1s88+u6meJGnPnj1NLztRsOcHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAKH91d6sbG8aO777333tzazTenH2cwY8aMZP3IkSPJetH58AcffDC3NjQ0lFz2iSeeSNbffPPNZL1Kg4ODyfp5552XrKc+t0svvTS57Isvvpisd7IyH90NYAIi/EBQhB8IivADQRF+ICjCDwRF+IGguJ+/Qb29vbm1ovP4AwMDyfo999yTrG/dujVZH68WLlyYrM+cObOl9R87diy3Np7P45eFPT8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBFV4nt/M5kp6RNI5ko5L6nf3n5vZDEmbJZ0vaVDSUnf/T3Wt1uuaa67Jra1duza57K233lp2OxPChRdemKx3dXW1tP5du3a1tPxE18ie/6ikO9z9i5K+Ium7ZvYlSaslPe3uF0h6OnsPYJwoDL+7D7v7ruz1+5J2SzpX0mJJG7LZNki6tqomAZTvlL7zm9n5ki6W9Lyk2e4+LI38gpA0q+zmAFSn4Wv7zWyapN9Ius3d/9vo+HFm1iepr7n2AFSloT2/mU3VSPA3uvtvs8n7zGxOVp8jaf9Yy7p7v7v3uHtPGQ0DKEdh+G1kF/+wpN3u/pNRpW2SVmSvV0iamLeeARNU4aO7zewySTskvaKRU32StEYj3/u3SPqMpD2SvunuBwrWNW4f3Y3ybdy4MVm/4YYbkvUPP/wwWV+yZElu7cknn0wuO541+ujuwu/87v5nSXkru/JUmgLQObjCDwiK8ANBEX4gKMIPBEX4gaAIPxAUj+5GpYaHh3Nrs2a1djtI0S27E/lcfhnY8wNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUJznR6VSw5dPmpTe9xTdr180tDnS2PMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCc50dLVq5cmaxPmZL/T+zw4cPJZW+//fZknfv1W8OeHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCMndPz2A2V9Ijks6RdFxSv7v/3MzWSbpJ0rvZrGvc/fcF60pvDB1n6tSpyfpbb72VrM+ePTu3tn379uSyixYtStYxNne3RuZr5CKfo5LucPddZnaGpAEzeyqr/dTdf9xskwDqUxh+dx+WNJy9ft/Mdks6t+rGAFTrlL7zm9n5ki6W9Hw2aaWZvWxm681ses4yfWa208x2ttQpgFI1HH4zmybpN5Juc/f/SvqFpM9Lmq+RI4P7x1rO3fvdvcfde0roF0BJGgq/mU3VSPA3uvtvJcnd97n7MXc/LumXkhZU1yaAshWG38xM0sOSdrv7T0ZNnzNqtiWSXi2/PQBVaeSv/QslfUvSK2b2UjZtjaTlZjZfkksalHRzJR2iVkWngjdt2pSsDwwM5NY2b97cVE8oRyN/7f+zpLHOGybP6QPobFzhBwRF+IGgCD8QFOEHgiL8QFCEHwiq8JbeUjfGLb1A5Rq9pZc9PxAU4QeCIvxAUIQfCIrwA0ERfiAowg8E1e4hut+T9K9R72dm0zpRp/bWqX1J9NasMns7r9EZ23qRzyc2brazU5/t16m9dWpfEr01q67eOOwHgiL8QFB1h7+/5u2ndGpvndqXRG/NqqW3Wr/zA6hP3Xt+ADWpJfxmdpWZ/c3M3jCz1XX0kMfMBs3sFTN7qe4hxrJh0Pab2aujps0ws6fM7B/ZzzGHSaupt3Vm9u/ss3vJzL5eU29zzexPZrbbzF4zs+9l02v97BJ91fK5tf2w38wmS/q7pEWShiS9IGm5u/+1rY3kMLNBST3uXvs5YTP7qqRDkh5x9+5s2o8kHXD3H2a/OKe7+/c7pLd1kg7VPXJzNqDMnNEjS0u6VtK3VeNnl+hrqWr43OrY8y+Q9Ia7/9Pdj0j6taTFNfTR8dz9WUkHTpq8WNKG7PUGjfzjabuc3jqCuw+7+67s9fuSTowsXetnl+irFnWE/1xJb496P6TOGvLbJf3RzAbMrK/uZsYwOxs2/cTw6bNq7udkhSM3t9NJI0t3zGfXzIjXZasj/GM9YqiTTjksdPcvS7pa0nezw1s0pqGRm9tljJGlO0KzI16XrY7wD0maO+r9pyXtraGPMbn73uznfkm/U+eNPrzvxCCp2c/9Nffzf500cvNYI0urAz67Thrxuo7wvyDpAjP7rJl9StIySdtq6OMTzKwr+0OMzKxL0tfUeaMPb5O0Inu9QtLWGnv5mE4ZuTlvZGnV/Nl12ojXtVzkk53K+JmkyZLWu/sP2t7EGMzscxrZ20sjdzxuqrM3M3tUUq9G7vraJ+luSY9L2iLpM5L2SPqmu7f9D285vfVq5ND1/yM3n/iO3ebeLpO0Q9Irko5nk9do5Pt1bZ9doq/lquFz4wo/ICiu8AOCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/ENT/AOZpEMJau0xcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building neural networks :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Five Layer Neural Network :\n",
    "\n",
    "1. Layer one - 200 Neurons Sigmoid act.\n",
    "2. Layer two - 100 Neurons Sigmoid act.\n",
    "3. Layer three - 60 Neurons Sigmoid act.\n",
    "4. Layer four - 30 Neurons Sigmoid act.\n",
    "5. Layer five - 10 Neurons Softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorflow.python.framework import ops\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting FFNN/train-images-idx3-ubyte.gz\n",
      "Extracting FFNN/train-labels-idx1-ubyte.gz\n",
      "Extracting FFNN/t10k-images-idx3-ubyte.gz\n",
      "Extracting FFNN/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "logs_path = 'log_sigmoid/' # logging path\n",
    "batch_size = 100 # batch size while performing training \n",
    "learning_rate = 0.003 # Learning rate \n",
    "training_epochs = 10 # training epoch\n",
    "display_epoch = 1\n",
    "mnist = input_data.read_data_sets(path, one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the input layer :\n",
    "\n",
    "Input layer a 2d tensor which consist of n samples, each sample has 784 dimensions. Since the number of samples in training dataset can vary, we specify variable number of rows using the \"None\" option when declaring shape of tensor. Also the tensor which will hold the train data will be a placeholder as it does not need any modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 784], name=\"InputData\") # tensor of input data of size n*784 dimensions\n",
    "XX = tf.reshape(X, [-1, 784]) # -1 is to transpose\n",
    "Y_ = tf.placeholder(tf.float32, [None, 10], name=\"LabelData\") # tensor of labels of size n*784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the first Layer :\n",
    "\n",
    "Each node in the first layer recieves the pixels of the image combined with the weights and bias term. This layer contains 200 Neurons.\n",
    "\n",
    "Each node recieves the input as - inp = w(transpose) * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 200\n",
    "# Since the data is 784 dimensional there must be 784 weights and 1 bias.\n",
    "W1 = tf.Variable(tf.truncated_normal([784, L], stddev=0.1)) # initializing random weights for layer 1.\n",
    "B1 = tf.Variable(tf.zeros([L])) # Bias vector for layer 2.\n",
    "\n",
    "# The output is calculated as wtranspose * x + b or xtranspose * w + b and then sigmoid function is applied on it.\n",
    "Y1 = tf.nn.sigmoid(tf.matmul(XX, W1) + B1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the second Layer :\n",
    "\n",
    "The second layer recieves as input the output of previous layer that is Y1. And again multiples the Y1 with weights and adds a bias term to generate output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 100\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([L, M], stddev=0.1)) # initializing random weights for layer 2.\n",
    "B2 = tf.Variable(tf.zeros([M])) # Bias vector for layer 2.\n",
    "\n",
    "# The output now -\n",
    "Y2 = tf.nn.sigmoid(tf.matmul(Y1, W2) + B2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the third layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 60\n",
    "W3 = tf.Variable(tf.truncated_normal([M, N], stddev=0.1)) # Initialize random weights for the hidden layer 3 \n",
    "B3 = tf.Variable(tf.zeros([N])) # Bias vector for layer 3\n",
    "\n",
    "Y3 = tf.nn.sigmoid(tf.matmul(Y2, W3) + B3) # Output from layer 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the fourth layer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = 30\n",
    "W4 = tf.Variable(tf.truncated_normal([N, O], stddev=0.1)) # Initialize random weights for the hidden layer 4\n",
    "B4 = tf.Variable(tf.zeros([O])) # Bias vector for layer 4\n",
    "\n",
    "Y4 = tf.nn.sigmoid(tf.matmul(Y3, W4) + B4) # Output from layer 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the fifth layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "W5 = tf.Variable(tf.truncated_normal([O, 10], stddev=0.1)) # Initialize random weights for the hidden layer 5 \n",
    "B5 = tf.Variable(tf.zeros([10])) # Bias vector for layer 5\n",
    "Ylogits = tf.matmul(Y4, W5) + B5 # computing the logits\n",
    "Y = tf.nn.softmax(Ylogits)# output from layer 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-866b75129e90>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cross entropy is basically our logistics loss for multiclass.\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits, labels=Y_) # final outcome using softmax cross entropy\n",
    "cost_op = tf.reduce_mean(cross_entropy)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction is correct if output is equal to actual Y_ is actual, Y is predicted\n",
    "correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(cost_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"cost\", cost_op)\n",
    "# Create a summary to monitor accuracy tensor\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "# Merge all summaries into a single op\n",
    "summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Optimization Finished!\n",
      "Accuracy:  0.9735\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "with tf.Session() as sess:\n",
    "    # Run the initializer\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # op to write logs to TensorBoard\n",
    "    writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        batch_count = int(mnist.train.num_examples/batch_size)\n",
    "        for i in range(batch_count):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            _,summary = sess.run([train_op, summary_op], feed_dict={X: batch_x, Y_: batch_y})\n",
    "            writer.add_summary(summary, epoch * batch_count + i)\n",
    "               \n",
    "        print(\"Epoch: \", epoch)\n",
    "        \n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Accuracy: \", accuracy.eval(feed_dict={X: mnist.test.images, Y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Multi-Layer Perceptron : \n",
    "\n",
    "1. Also a Feed Forward Neural Network.\n",
    "2. Completely Connected.\n",
    "3. Can be used for classification and regression.\n",
    "\n",
    "Dataset to be used - https://archive.ics.uci.edu/ml/datasets/bank+marketing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Datasets/bank-additional-full.csv', sep=\";\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperating categorical and quantative features.\n",
    "var_names = data.columns.tolist()\n",
    "categs = ['job','marital','education','default','housing','loan','contact','month','day_of_week','duration','poutcome','y']\n",
    "quantit = [i for i in var_names if i not in categs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHot encoding for categorical features.\n",
    "job = pd.get_dummies(data['job'])\n",
    "marital = pd.get_dummies(data['marital'])\n",
    "education = pd.get_dummies(data['education'])\n",
    "default = pd.get_dummies(data['default'])\n",
    "housing = pd.get_dummies(data['housing'])\n",
    "loan = pd.get_dummies(data['loan'])\n",
    "contact = pd.get_dummies(data['contact'])\n",
    "month = pd.get_dummies(data['month'])\n",
    "day = pd.get_dummies(data['day_of_week'])\n",
    "duration = pd.get_dummies(data['duration'])\n",
    "poutcome = pd.get_dummies(data['poutcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the variable to be predicted..\n",
    "dict_map = dict()\n",
    "y_map = {'yes':1,'no':0}\n",
    "dict_map['y'] = y_map\n",
    "data = data.replace(dict_map)\n",
    "label = data['y']\n",
    "df_numerical = data[quantit]\n",
    "df_names = df_numerical .keys().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed  y  \n",
       "0          93.994          -36.4      4.857       5191.0  0  \n",
       "1          93.994          -36.4      4.857       5191.0  0  \n",
       "2          93.994          -36.4      4.857       5191.0  0  \n",
       "3          93.994          -36.4      4.857       5191.0  0  \n",
       "4          93.994          -36.4      4.857       5191.0  0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakhar\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.246914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.283951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  campaign  pdays  previous  emp.var.rate  cons.price.idx  \\\n",
       "0  0.481481       0.0    1.0       0.0        0.9375        0.698753   \n",
       "1  0.493827       0.0    1.0       0.0        0.9375        0.698753   \n",
       "2  0.246914       0.0    1.0       0.0        0.9375        0.698753   \n",
       "3  0.283951       0.0    1.0       0.0        0.9375        0.698753   \n",
       "4  0.481481       0.0    1.0       0.0        0.9375        0.698753   \n",
       "\n",
       "   cons.conf.idx  euribor3m  nr.employed  \n",
       "0        0.60251   0.957379     0.859735  \n",
       "1        0.60251   0.957379     0.859735  \n",
       "2        0.60251   0.957379     0.859735  \n",
       "3        0.60251   0.957379     0.859735  \n",
       "4        0.60251   0.957379     0.859735  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling the dataset.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(df_numerical)\n",
    "df_temp = pd.DataFrame(x_scaled)\n",
    "df_temp.columns = df_names\n",
    "\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>admin.</th>\n",
       "      <th>...</th>\n",
       "      <th>3322</th>\n",
       "      <th>3366</th>\n",
       "      <th>3422</th>\n",
       "      <th>3509</th>\n",
       "      <th>3631</th>\n",
       "      <th>3643</th>\n",
       "      <th>3785</th>\n",
       "      <th>4199</th>\n",
       "      <th>4918</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.246914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.283951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1607 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  campaign  pdays  previous  emp.var.rate  cons.price.idx  \\\n",
       "0  0.481481       0.0    1.0       0.0        0.9375        0.698753   \n",
       "1  0.493827       0.0    1.0       0.0        0.9375        0.698753   \n",
       "2  0.246914       0.0    1.0       0.0        0.9375        0.698753   \n",
       "3  0.283951       0.0    1.0       0.0        0.9375        0.698753   \n",
       "4  0.481481       0.0    1.0       0.0        0.9375        0.698753   \n",
       "\n",
       "   cons.conf.idx  euribor3m  nr.employed  admin. ...  3322  3366  3422  3509  \\\n",
       "0        0.60251   0.957379     0.859735       0 ...     0     0     0     0   \n",
       "1        0.60251   0.957379     0.859735       0 ...     0     0     0     0   \n",
       "2        0.60251   0.957379     0.859735       0 ...     0     0     0     0   \n",
       "3        0.60251   0.957379     0.859735       1 ...     0     0     0     0   \n",
       "4        0.60251   0.957379     0.859735       0 ...     0     0     0     0   \n",
       "\n",
       "   3631  3643  3785  4199  4918  y  \n",
       "0     0     0     0     0     0  0  \n",
       "1     0     0     0     0     0  0  \n",
       "2     0     0     0     0     0  0  \n",
       "3     0     0     0     0     0  0  \n",
       "4     0     0     0     0     0  0  \n",
       "\n",
       "[5 rows x 1607 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining the onehot encoded features and numerical features into a single dataframe :\n",
    "normalized_df = pd.concat([df_temp,\n",
    "                      job,\n",
    "                      marital,\n",
    "                      education,\n",
    "                      default,\n",
    "                      housing,\n",
    "                      loan,\n",
    "                      contact,\n",
    "                      month,\n",
    "                      day,\n",
    "                      poutcome,\n",
    "                      duration,\n",
    "                      label], axis=1)\n",
    "\n",
    "normalized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Columns: 1607 entries, age to y\n",
      "dtypes: float64(9), int64(1), uint8(1597)\n",
      "memory usage: 65.9 MB\n"
     ]
    }
   ],
   "source": [
    "normalized_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Dataframe to CSV.\n",
    "normalized_df.to_csv('Datasets/bank_normalized.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing an MLP for Client Subscription Assessment :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = 'Datasets/bank_normalized.csv'         # Path to .csv dataset \n",
    "raw_data = pd.read_csv(FILE_PATH)        # Open raw .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Columns: 1607 entries, age to y\n",
      "dtypes: float64(9), int64(1598)\n",
      "memory usage: 505.0 MB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_LABEL = 'y'    # Name of the variable to be predicted\n",
    "KEYS = [i for i in raw_data.keys().tolist() if i != Y_LABEL]# Name of predictors\n",
    "N_INSTANCES = raw_data.shape[0]       # Number of instances\n",
    "N_INPUT = raw_data.shape[1] - 1            # Input size\n",
    "N_CLASSES = raw_data[Y_LABEL].unique().shape[0] # Number of classes\n",
    "TEST_SIZE = 0.25         # Test set size (% of dataset)\n",
    "TRAIN_SIZE = int(N_INSTANCES * (1 - TEST_SIZE))  # Train size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predictors \t1606\n",
      "Number of classes \t2\n",
      "Number of instances \t41188\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of predictors \\t%s\" %(N_INPUT))\n",
    "print(\"Number of classes \\t%s\" %(N_CLASSES))\n",
    "print(\"Number of instances \\t%s\" %(N_INSTANCES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the parameters of MLP\n",
    "LEARNING_RATE = 0.001     # learning rate\n",
    "TRAINING_EPOCHS = 100     # number of training epoch for the forward pass\n",
    "BATCH_SIZE = 100     # batch size to be used during training\n",
    "DISPLAY_STEP = 20   # print the error etc. at each 20 step\n",
    "HIDDEN_SIZE = 256   # number of neurons in each hidden layer\n",
    "# We use tanh as the activation function, but you can try using ReLU as well\n",
    "ACTIVATION_FUNCTION_OUT = tf.nn.relu\n",
    "STDDEV = 0.1        # Standard Deviations\n",
    "RANDOM_STATE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_data[KEYS].get_values()       # X data\n",
    "labels = raw_data[Y_LABEL].get_values()  # y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coding the labels for softmax.\n",
    "labels_ = np.zeros((N_INSTANCES, N_CLASSES))\n",
    "labels_[np.arange(N_INSTANCES), labels] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into 75 and 25 % data for train and test.\n",
    "data_train,data_test,labels_train,labels_test = train_test_split(data,labels_,test_size = TEST_SIZE,random_state = RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4 Hidden Layer MLP :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = N_INPUT                   # input n labels \n",
    "n_hidden_1 = HIDDEN_SIZE            # 1st layer \n",
    "n_hidden_2 = HIDDEN_SIZE            # 2nd layer\n",
    "n_hidden_3 = HIDDEN_SIZE            # 3rd layer \n",
    "n_hidden_4 = HIDDEN_SIZE            # 4th layer \n",
    "n_classes = N_CLASSES               # output m classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input shape is None * number of input\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "# label shape is None * number of classes\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# For dropout ..\n",
    "dropout_keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the layers structure of MLP...\n",
    "def DeepMLPClassifier(_X, _weights, _biases, dropout_keep_prob):\n",
    "    layer1 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(_X, _weights['w1']), _biases['b1'])), dropout_keep_prob)\n",
    "    layer2 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(layer1, _weights['w2']), _biases['b2'])), dropout_keep_prob)\n",
    "    layer3 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(layer2, _weights['w3']), _biases['b3'])), dropout_keep_prob)\n",
    "    layer4 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(layer3, _weights['w4']), _biases['b4'])), dropout_keep_prob)\n",
    "    out = ACTIVATION_FUNCTION_OUT(tf.add(tf.matmul(layer4, _weights['out']), _biases['out']))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We didnt define the weights and biases..\n",
    "weights = {\n",
    "    'w1': tf.Variable(tf.random_normal([n_input, n_hidden_1],stddev=STDDEV)),\n",
    "    'w2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2],stddev=STDDEV)),\n",
    "    'w3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3],stddev=STDDEV)),\n",
    "    'w4': tf.Variable(tf.random_normal([n_hidden_3, n_hidden_4],stddev=STDDEV)),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_4, n_classes],stddev=STDDEV)),   \n",
    "}\n",
    "biases = { \n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])), \n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])), \n",
    "    'b3': tf.Variable(tf.random_normal([n_hidden_3])), \n",
    "    'b4': tf.Variable(tf.random_normal([n_hidden_4])), \n",
    "    'out': tf.Variable(tf.random_normal([n_classes])) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Predictions.\n",
    "pred = DeepMLPClassifier(X, weights, biases, dropout_keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the loss.\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=y))\n",
    "\n",
    "# Optimization op (backprop) \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = LEARNING_RATE).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0/100 cost: 0.287145767\n",
      "Training accuracy: 0.910\n",
      "Epoch:  20/100 cost: 0.007006067\n",
      "Training accuracy: 1.000\n",
      "Epoch:  40/100 cost: 0.001338693\n",
      "Training accuracy: 1.000\n",
      "Epoch:  60/100 cost: 0.000648487\n",
      "Training accuracy: 1.000\n",
      "Epoch:  80/100 cost: 0.000250678\n",
      "Training accuracy: 1.000\n",
      "Your MLP model has been trained successfully.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(TRAINING_EPOCHS):\n",
    "    avg_cost = 0.0\n",
    "    total_batch = int(data_train.shape[0] / BATCH_SIZE)\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        randidx = np.random.randint(int(TRAIN_SIZE), size = BATCH_SIZE)\n",
    "        batch_xs = data_train[randidx, :]\n",
    "        batch_ys = labels_train[randidx, :]\n",
    "        # Fit using batched data\n",
    "        sess.run(optimizer, feed_dict={X: batch_xs, y: batch_ys, dropout_keep_prob: 0.9})\n",
    "        # Calculate average cost\n",
    "        avg_cost += sess.run(cost, feed_dict={X: batch_xs, y: batch_ys, dropout_keep_prob:1.})/total_batch\n",
    "    # Display progress\n",
    "    if epoch % DISPLAY_STEP == 0:\n",
    "        print(\"Epoch: %3d/%3d cost: %.9f\" % (epoch, TRAINING_EPOCHS, avg_cost))\n",
    "        train_acc = sess.run(accuracy, feed_dict={X: batch_xs, y: batch_ys, dropout_keep_prob:1.})\n",
    "        print(\"Training accuracy: %.3f\" % (train_acc))\n",
    "print(\"Your MLP model has been trained successfully.\")\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
